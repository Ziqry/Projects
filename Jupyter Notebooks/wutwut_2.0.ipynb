{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log2\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification  # To create synthetic classification data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder  # For converting categorical to numeric\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC  # Support Vector Machine (SVM) model\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading files & Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/...'\n",
    "filename = '....xlsx/csv'\n",
    "df = pd.read_excel(path + filename)\n",
    "df = pd.read_csv(path + filename)\n",
    "\n",
    "# to upload files into google colab\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save results to an Excel file\n",
    "results.to_excel(\"prediction_results.xlsx\", index=False)\n",
    " \n",
    "# Step 7: Download the Excel file\n",
    "from google.colab import files\n",
    "files.download(\"prediction_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.head()\n",
    "df.tail()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check value counts\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual entropy and info gain demo\n",
    "def entropy(class_counts):\n",
    "    total = sum(class_counts)\n",
    "    return -sum((count / total) * log2(count / total) if count else 0 for count in class_counts)\n",
    " \n",
    "base_entropy = entropy([6, 4])\n",
    "print(\"\\nBase Entropy:\", base_entropy)\n",
    " \n",
    "split_entropy = ((5/10) * entropy([4, 1])) + ((5/10) * entropy([2, 3]))\n",
    "info_gain = base_entropy - split_entropy\n",
    "print(\"Information Gain from split:\", info_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6e6ebb045939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Histogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Distribution of Risk Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Risk_Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Distribution of Risk Score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Risk Score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "# Histogram\n",
    "# Distribution of Risk Score\n",
    "sns.histplot(df['Risk_Score'], bins=20, kde=True)\n",
    "plt.title(\"Distribution of Risk Score\")\n",
    "plt.xlabel(\"Risk Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot - Transaction Amount by High Value Flag\n",
    "sns.boxplot(x='High_Value_Flag', y='Transaction_Amount', data=df)\n",
    "plt.title(\"High Value Flag vs. Transaction Amount\")\n",
    "plt.xlabel(\"High Value Transaction (True/False)\")\n",
    "plt.ylabel(\"Transaction Amount\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barchart\n",
    "avg_risk = df.groupby(\"Department\")[\"Risk_Score\"].mean().reset_index()\n",
    "sns.barplot(x='Risk_Score', y='Department', data=avg_risk)\n",
    "plt.title(\"Average Risk Score by Department\")\n",
    "plt.xlabel(\"Average Risk Score\")\n",
    "plt.ylabel(\"Department\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df[\"Transaction_Time\"], df[\"Risk_Score\"], alpha=0.8)\n",
    "plt.title(\"Scatter Plot of Transaction_Time vs Risk_score\")\n",
    "plt.xlabel(\"Transaction_Time\")\n",
    "plt.ylabel(\"Risk_score\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Use Mean Imputation:\n",
    "- When the feature is numerical and follows a normal (symmetric) distribution.\n",
    "- Example: Temperature, height, age (if no outliers).\n",
    "\n",
    "✅ Use Median Imputation:\n",
    "- When the feature is numerical but the data is skewed or has outliers.\n",
    "- Example: Income, house prices, CO2 emission (skewed data).\n",
    "\n",
    "✅ Use Mode Imputation:\n",
    "- When the feature is categorical.\n",
    "- Example: Gender, Color, Type, Brand.\n",
    "\n",
    "\n",
    "| Data Type | Distribution | Outliers Present? | Use |\n",
    "|-----------|--------------|-------------------|-----|\n",
    "| Numerical | Normal        | No                | Mean |\n",
    "| Numerical | Skewed        | Yes               | Median |\n",
    "| Categorical | -           | -                 | Mode |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 Best Practices:\n",
    "Impute after splitting into train/test (to avoid data leakage).\n",
    "\n",
    "If many values are missing (>30%), consider dropping the column or using advanced techniques like KNN imputation, IterativeImputer, or even model-based imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check skewness\n",
    "df['Income'].skew()  # > 1 or < -1 = highly skewed\n",
    "\n",
    "# plot distribution\n",
    "import seaborn as sns\n",
    "sns.histplot(df['Income'], kde=True)\n",
    "\n",
    "# check outliers with boxplot\n",
    "sns.boxplot(x=df['Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Fill missing values in a column with the column mean\n",
    "df['column_name'].fillna(df['column_name'].mean(), inplace=True)\n",
    "# Fill missing values in a column with the column mode\n",
    "df['column_name'].fillna(df['column_name'].mode(), inplace=True)\n",
    "\n",
    "# print original data and cleaned data to compare\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of features that actually exist in the dataset\n",
    "features = ['Transaction_Amount', 'Vendor_Risk_Rating',\n",
    "            'After_Hours', 'High_Value_Flag',\n",
    "            'Department_Risk_Score', 'Approval_Steps']\n",
    " \n",
    "# Assign the selected features to X (input variables)\n",
    "X = df[features]\n",
    " \n",
    "# Define the target variable (what we want to predict)\n",
    "y = df['High_Value_Flag']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean features to numeric format\n",
    "X['High_Value_Flag'] = X['High_Value_Flag'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "✅ Robust to Outliers\n",
    "These models are not easily distorted by outliers:\n",
    "| Model | Why It's Robust |\n",
    "|-------|------------------|\n",
    "| **Tree-based models** (e.g. Random Forest, XGBoost) | Split data based on thresholds, not affected by extreme values |\n",
    "| **Huber Regressor** (from `sklearn`) | Combines least squares and robust loss |\n",
    "| **RANSAC Regressor** | Actively filters out outliers during training |\n",
    "| **Isolation Forest** | Specifically built for anomaly detection |\n",
    "| **Quantile Regression** | Models conditional medians, less sensitive to outliers |\n",
    "\n",
    "\n",
    "❌ Sensitive to Outliers\n",
    "These models assume normally distributed, clean data:\n",
    "| Model | Why It's Sensitive |\n",
    "|-------|--------------------|\n",
    "| **Linear Regression** | Uses squared error → outliers dominate loss |\n",
    "| **Logistic Regression** | Sensitive to extreme values in features |\n",
    "| **K-Nearest Neighbors (KNN)** | Distance-based — outliers mess up neighborhoods |\n",
    "| **SVM (with linear kernel)** | Can be distorted unless using robust kernel or outlier detection first |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what do we do with outliers?\n",
    "\n",
    "✅ Option 1: Keep them\n",
    "When: If they are genuine values, not data entry errors.\n",
    "Use robust models (like Random Forest or Huber Regressor) that are less sensitive to outliers.\n",
    "\n",
    "❌ Option 2: Remove them\n",
    "When: Outliers result from data entry errors or are not relevant to your analysis.\n",
    "Use .drop() after filtering out using IQR or Z-score.\n",
    "\n",
    "🔁 Option 3: Transform them\n",
    "Apply log, square root, or box-cox transformations to reduce the effect of outliers.\n",
    "\n",
    "🧪 Option 4: Cap or impute them\n",
    "Replace extreme values with thresholds (called Winsorization).\n",
    "Or replace with the median or a predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting outliers using IQR\n",
    "df = pd.read_csv(\"cars.csv\")\n",
    "\n",
    "Q1 = df['CO2'].quantile(0.25)\n",
    "Q3 = df['CO2'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Outlier condition\n",
    "outliers = df[(df['CO2'] < Q1 - 1.5 * IQR) | (df['CO2'] > Q3 + 1.5 * IQR)]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply log, square root or box-cox transformation to reduce effect of outliers\n",
    "import numpy as np\n",
    "df['CO2_log'] = np.log(df['CO2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for outliers using interquartile range in all numerical columns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"cars.csv\")\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_cols = df.select_dtypes(include='number')\n",
    "\n",
    "# Detect outliers using IQR for each numeric column\n",
    "for col in numeric_cols.columns:\n",
    "    Q1 = numeric_cols[col].quantile(0.25)\n",
    "    Q3 = numeric_cols[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = numeric_cols[(numeric_cols[col] < Q1 - 1.5 * IQR) | (numeric_cols[col] > Q3 + 1.5 * IQR)]\n",
    "    \n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Number of outliers: {outliers.shape[0]}\")\n",
    "    print(outliers[[col]])\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all outliers from the dataset\n",
    "filtered_df = df.copy()\n",
    "\n",
    "# Loop through each numeric column\n",
    "for col in numeric_cols.columns:\n",
    "    Q1 = filtered_df[col].quantile(0.25)\n",
    "    Q3 = filtered_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # Keep only rows within IQR range\n",
    "    filtered_df = filtered_df[(filtered_df[col] >= Q1 - 1.5 * IQR) & (filtered_df[col] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "print(\"Filtered data shape:\", filtered_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate Outliers\n",
    "are data points that may look normal when considered individually (univariate) but become outliers when considering combinations of features.\n",
    "\n",
    "Example:\n",
    "- A car with very high weight may seem normal.\n",
    "- A car with very high volume may also seem normal.\n",
    "- But a car with very high weight and very low volume could be unusual together — a multivariate outlier.\n",
    "\n",
    "Common detection methods:\n",
    "- Mahalanobis Distance (measures how far a point is from the mean in multidimensional space)\n",
    "- Isolation Forest\n",
    "- PCA-based anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis Distance Example (simplified for 2D)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "df = pd.read_csv(\"cars.csv\")\n",
    "X = df[['Weight', 'Volume']].dropna()\n",
    "\n",
    "mean = X.mean().values\n",
    "cov = np.cov(X.T)\n",
    "inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "X['mahalanobis'] = X.apply(lambda row: distance.mahalanobis(row, mean, inv_cov), axis=1)\n",
    "outliers = X[X['mahalanobis'] > 3]  # threshold can vary\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "# Avoid stratify if any class has < 2 samples\n",
    "if y.value_counts().min() < 2:\n",
    "    print(\"\\n⚠️ Skipping stratify due to small class size.\")\n",
    "    stratify_param = None\n",
    "else:\n",
    "    stratify_param = y\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=stratify_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on a similar column\n",
    "merged_data = pd.merge(df_1, df_2, on='similar_column', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate synthetic classification data\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,     # Total 1000 samples\n",
    "    n_features=10,      # Each sample has 10 features\n",
    "    n_classes=2,        # Binary classification (2 classes: 0 and 1)\n",
    "    random_state=42     # Seed for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Tranformation\n",
    "### Encoding categorical data\n",
    "- Categorical data is encoded to convert categorical data or tect data into numerical format\n",
    "- most ML algorithms work only with numerical data\n",
    "- encoding also helps to prevent bias in the model by ensuring that all features are equally weighted\n",
    "\n",
    "### Data normalization\n",
    "- is a form of feature scaling that transforms the range of features to a standard scale\n",
    "- data scaling is required when the dataset has features of varying ranges\n",
    "- normalized data enhance model performance and improve the accuracy of a model.\n",
    "- it helps algorithms that rely on distance metrics such as, KNN & SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variable column using one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['column_name'], drop_first=True)\n",
    "# can remove the \"drop_first=True\" as alternative\n",
    "df = pd.get_dummies(df, columns=['column_name'])\n",
    "\n",
    "# Normalize 'Income' column using Min-Max scaling\n",
    "df['Income_Normalized'] = (\n",
    "    (df['Income'] - df['Income'].min()) /\n",
    "    (df['Income'].max() - df['Income'].min())\n",
    ")\n",
    "\n",
    "# Convert EnrollmentDate to datetime\n",
    "df['column_name'] = pd.to_datetime(df['column_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all categorical columns into numeric values\n",
    "# This is necessary because certain machine learning model require all numerical input\n",
    "le = LabelEncoder()  # Create a LabelEncoder instance\n",
    "for column in df.columns:\n",
    "    df[column] = le.fit_transform(df[column])  # Encode each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced dataset\n",
    "\n",
    "A dataset is imbalanced when one class significantly outnumbers another.\n",
    "\n",
    "Example:\n",
    "- 95% of customers don’t churn.\n",
    "- 5% of customers churn.\n",
    "\n",
    "This can lead to a model that predicts only the majority class, but still shows high accuracy — while failing the real goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Resampling Methods\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| **Oversampling** (e.g. SMOTE) | Generate synthetic samples of the minority class |\n",
    "| **Undersampling** | Remove samples from the majority class |\n",
    "| **Hybrid** | Combine both |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "sm = SMOTE()\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Algorithmic Strategies\n",
    "\n",
    "| Strategy | Description |\n",
    "|----------|-------------|\n",
    "| **Class weights** | Penalize misclassification of minority class more |\n",
    "| **Custom loss functions** | Modify loss to give more weight to minority class |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Proper Evaluation Metrics\n",
    "\n",
    "Use metrics that don't get fooled by accuracy:\n",
    "\n",
    "- Precision / Recall\n",
    "- F1-score\n",
    "- Confusion Matrix\n",
    "- AUC-ROC / Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Which Models Work Well with Imbalanced Datasets?\n",
    "\n",
    "| Model | Works Well? | Why? |\n",
    "|-------|-------------|------|\n",
    "| **Random Forest** | ✅ | Handles imbalance well; supports class weights |\n",
    "| **XGBoost / LightGBM** | ✅ | Allows built-in handling of imbalance (`scale_pos_weight`) |\n",
    "| **Logistic Regression (with class_weight)** | ✅ | Effective with weighting or resampling |\n",
    "| **SVM** | ⚠️ | Needs tuning or balancing |\n",
    "| **KNN** | ❌ | Distance-based; highly affected by imbalance |\n",
    "| **Naive Bayes** | ⚠️ | Can be misled by rare events unless priors are adjusted |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not useful for analysis\n",
    "df_3 = df.drop(columns=['ID', 'client_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ML Algorithm               | Classification | Regression | Notes                                                               |\n",
    "| -------------------------- | -------------- | ---------- | ------------------------------------------------------------------- |\n",
    "| **Linear Regression**      | ❌              | ✅          | Simple and interpretable; good for linear relationships.            |\n",
    "| **Logistic Regression**    | ✅              | ❌          | For binary classification; not used for regression.                 |\n",
    "| **Decision Tree**          | ✅              | ✅          | Easy to interpret; prone to overfitting.                            |\n",
    "| **Random Forest**          | ✅              | ✅          | Handles non-linearity well; more robust than decision trees.        |\n",
    "| **Gradient Boosting**      | ✅              | ✅          | Accurate; used in competitions (e.g., XGBoost, LightGBM, CatBoost). |\n",
    "| **XGBoost**                | ✅              | ✅          | Fast and powerful; great with tabular data.                         |\n",
    "| **LightGBM**               | ✅              | ✅          | Faster alternative to XGBoost; great with large datasets.           |\n",
    "| **CatBoost**               | ✅              | ✅          | Handles categorical data well; easy to use.                         |\n",
    "| **Support Vector Machine** | ✅              | ✅          | Good for small to medium datasets; requires scaling.                |\n",
    "| **K-Nearest Neighbors**    | ✅              | ✅          | Simple; can struggle with large datasets or many features.          |\n",
    "| **Naive Bayes**            | ✅              | ❌          | Only for classification; assumes feature independence.              |\n",
    "| **Neural Networks (MLP)**  | ✅              | ✅          | Flexible; works for both tasks but may need more data/tuning.       |\n",
    "| **Ridge/Lasso Regression** | ❌              | ✅          | Regularized linear models for regression.                           |\n",
    "| **ElasticNet**             | ❌              | ✅          | Combines Ridge and Lasso for regression.                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting feature and target\n",
    "x = df['Weight']\n",
    "y = df['CO2']\n",
    "\n",
    "# calculate linear regression\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "def predict(weight):\n",
    "    return slope * weight + intercept\n",
    "\n",
    "# apply to x\n",
    "mymodel = list(map(predict, x))\n",
    "\n",
    "# charts\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, mymodel, color='red')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('CO2 Emission')\n",
    "plt.title('Linear Regression: CO2 vs Weight')\n",
    "plt.show()\n",
    "\n",
    "# example prediction\n",
    "print(\"Predicted CO2 for a car weighing 2300kg:\", predict(2300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting weight and volume for features and co2 as target\n",
    "X = df[['Weight', 'Volume']]\n",
    "y = df['CO2']\n",
    "\n",
    "# create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# prediction\n",
    "predictedCO2 = model.predict([[2300, 1300]])\n",
    "print(\"Predicted CO2 (Weight=2300kg, Volume=1300cm3):\", predictedCO2[0])\n",
    "\n",
    "# show coefficients\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variables\n",
    "x = df['Weight']\n",
    "y = df['CO2']\n",
    "\n",
    "# fit polynomial regression\n",
    "model = np.poly1d(np.polyfit(x, y, 2))\n",
    "\n",
    "# create line points\n",
    "x_line = np.linspace(min(x), max(x), 100)\n",
    "y_line = model(x_line)\n",
    "\n",
    "# charts\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x_line, y_line, color='green')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('CO2 Emission')\n",
    "plt.title('Polynomial Regression: CO2 vs Weight')\n",
    "plt.show()\n",
    "\n",
    "# r-squared score\n",
    "print(\"R-squared:\", r2_score(y, model(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check skewness\n",
    "df['Income'].skew() # > 1 or < -1 = highly skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution\n",
    "import seaborn as sns\n",
    "sns.histplot(df['Income'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check outliers with boxplot\n",
    "sns.boxplot(x=df['Income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Train a Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# Step 9: Evaluate the model using predictions and metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Predict outcomes for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Low Risk', 'High Risk'],\n",
    "            yticklabels=['Low Risk', 'High Risk'])\n",
    "plt.title(\"Confusion Matrix - Audit Risk Classification (Decision Tree)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    " \n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training decision tree model with entropy criterion\n",
    "#  Train a Decision Tree model\n",
    "model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the output using the trained model\n",
    "y_pred = model.predict(X)  # Predict on the training data itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "# checking accuracy\n",
    "acc_rf = accuracy_score(y_test, rf_preds)\n",
    "model_names.append('Random Forest')\n",
    "accuracy_scores.append(acc_rf)\n",
    "print(\"\\nRandom Forest Accuracy:\", acc_rf)\n",
    "print(classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor  # For regression\n",
    "\n",
    "model = RandomForestRegressor()  # Instead of RandomForestClassifier\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict outcomes for the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "et_model = ExtraTreesClassifier(n_estimators=100, criterion='entropy', random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "et_preds = et_model.predict(X_test)\n",
    "\n",
    "# checking accuracy\n",
    "acc_et = accuracy_score(y_test, et_preds)\n",
    "model_names.append('Extra Trees')\n",
    "accuracy_scores.append(acc_et)\n",
    "print(\"\\nExtra Trees Accuracy:\", acc_et)\n",
    "print(classification_report(y_test, et_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train Support Vector Machine Classifier\n",
    "svm_model = SVC(probability=True, random_state=42)  # Initialize model with probability enabled\n",
    "svm_model.fit(X_train, y_train)                     # Train on training data\n",
    "svm_preds = svm_model.predict(X_test)               # Predict on test data\n",
    "svm_accuracy = accuracy_score(y_test, svm_preds)    # Calculate accuracy\n",
    "svm_risk_scores = svm_model.predict_proba(X_test)[:, 1]  # Probability of class 1 (risk score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intepreting **Regression Model** Performance Metrix\n",
    "- r2_score - the proportion of variance in the dependent variable that's predictable from independent variables\n",
    "\n",
    "    - Interpretation:\n",
    "        - 1.0 = perfect prediction\n",
    "        - 0.9999... = nearly perfect (99.999% of variance explained)\n",
    "        - 0.8-0.9 is generally considered excellent for real-world applications\n",
    "    - Caution: Values this high often indicate:\n",
    "        - Possible data leakage (test data influencing training)\n",
    "        - Overly simple dataset (maybe the problem is trivial)\n",
    "        - Target variable might be included in features\n",
    "\n",
    "- MAE - mean absolute error - average absolute difference between predictions and actual values\n",
    "    \n",
    "    - Interpretation:\n",
    "        - On average, your predictions are off by about 868.45 units (if MAE = 868.45)\n",
    "        - Example: If predicting house prices where average price is $500,000, this is excellent (~1.7% error)\n",
    "        - If predicting temperatures where average is 50°F, this would be poor\n",
    "\n",
    "- MSE - Mean Squared Error - average of squared errors\n",
    "    - Interpretation:\n",
    "        - More sensitive to large errors than MAE\n",
    "        - Hard to interpret alone due to squaring\n",
    "        - Primarily useful for comparing models (lower is better)\n",
    "\n",
    "- RMSE - Root Mean Squared Error - square root of MSE\n",
    "    - Interpretation:\n",
    "        - In the same units as your original data\n",
    "        - Your typical prediction error is about 6.57 units\n",
    "        - More interpretable than MSE\n",
    "        - RMSE > MAE suggests some larger errors in your dataset. However, this is normal for real-world data with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print score and model performance\n",
    "# Key Metrics\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')  # Perfect prediction line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing model performance\n",
    "#  Print Accuracy Results\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")  # Display Random Forest accuracy\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.2f}\")           # Display SVM accuracy\n",
    " \n",
    "#  Plot Accuracy Comparison - First display\n",
    "models = ['Random Forest', 'SVM']    # Model names for x-axis\n",
    "accuracies = [rf_accuracy, svm_accuracy]  # Accuracy values\n",
    " \n",
    "plt.figure(figsize=(8, 5))           # Set figure size\n",
    "plt.bar(models, accuracies)          # Create bar chart\n",
    "plt.title('Model Accuracy Comparison')  # Title of the plot\n",
    "plt.ylabel('Accuracy')               # Y-axis label\n",
    "plt.ylim(0, 1)                       # Limit y-axis from 0 to 1\n",
    "plt.grid(axis='y')                   # Show grid lines on y-axis\n",
    "plt.show()                           # Display the plot\n",
    " \n",
    "# Save the Plot and Show Again (this part duplicates the plot and saves it)\n",
    "plt.figure(figsize=(8, 5))           # Create another figure with same settings\n",
    "plt.bar(models, accuracies)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y')\n",
    " \n",
    "plt.savefig(\"accuracy_plot.png\")     # Save the plot as an image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Evaluate the model using predictions and metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Predict outcomes for the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    " \n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Low Risk', 'High Risk'],\n",
    "            yticklabels=['Low Risk', 'High Risk'])\n",
    "plt.title(\"Confusion Matrix - Audit Risk Classification\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    " \n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new input sample with the same features used for training\n",
    "# Format: [Transaction_Amount, Vendor_Risk_Rating, After_Hours, High_Value_Flag, Department_Risk_Score, Approval_Steps]\n",
    "new_input = pd.DataFrame([[\n",
    "    1500,     # Transaction_Amount\n",
    "    1,        # Vendor_Risk_Rating\n",
    "    0,        # After_Hours (1 = yes, 0 = no)\n",
    "    0,        # High_Value_Flag (1 = high value)\n",
    "    2,       # Department_Risk_Score (example calculation: rating * steps)\n",
    "    3         # Approval_Steps\n",
    "]], columns=['Transaction_Amount', 'Vendor_Risk_Rating', 'After_Hours',\n",
    "             'High_Value_Flag', 'Department_Risk_Score', 'Approval_Steps'])\n",
    " \n",
    "# Scale the input using the previously fitted scaler\n",
    "new_input_scaled = scaler.transform(new_input)\n",
    " \n",
    "# Predict risk class (0 = Low Risk, 1 = High Risk)\n",
    "predicted_class = model.predict(new_input_scaled)\n",
    "predicted_prob = model.predict_proba(new_input_scaled)\n",
    " \n",
    "# Output results\n",
    "print(\"Predicted Risk Class:\", \"High Risk\" if predicted_class[0] else \"Low Risk\")\n",
    "print(\"Prediction Probabilities [Low Risk, High Risk]:\", predicted_prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot model comparison\n",
    "# ------------------------------------------\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(model_names, accuracy_scores, color='skyblue')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for i, score in enumerate(accuracy_scores):\n",
    "    plt.text(i, score + 0.02, f\"{score:.2f}\", ha='center', fontsize=12)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Visualize the Decision Tree\n",
    "# ------------------------------------------\n",
    "from sklearn.tree import plot_tree\n",
    " \n",
    "plt.figure(figsize=(20, 10))  # Adjust size as needed\n",
    "plot_tree(\n",
    "    dt_model,\n",
    "    feature_names=features,\n",
    "    class_names=[str(cls) for cls in np.unique(y)],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Make predictions and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    " \n",
    "#  Plot the Decision Tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(model, filled=True, feature_names=data.feature_names, class_names=data.target_names)\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the detailed classification metrics (precision, recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "What are these:\n",
    "- Gradient Boosted Trees - gradient boosting is a methodology applied on top of another machine learning algorithm and involves 2 types of models:\n",
    "    1. weak machine learning model, typically a decision tree\n",
    "    2. strong machine elarning model, composed of multiple weak models.\n",
    "    - At each step,a new weak model is trained to predict the error of the current strong model (pseudo response). Error = difference between prediction and regressive label. The weak model which is the error is then added to the strong model with a negative sign to reduce the error of the strong model.\n",
    "    - The operation repeats until a stopping criterion is met (maximum number of iterations) or if the strong model begins to overfit as measured on a separate validation dataset.\n",
    "    - shrinkage in gradient boosting is similar to learning rate in neural networks. It controls how fast the strong model is learning and helps to limit overfitting. The smaller the shrinkage the more it reduces overfitting.\n",
    "- Neural Networks\n",
    "    - mimics human brain, specifically neurons to identify phenomena, weigh options and make conclusions. \n",
    "    - consists of layers of nodes/artificial neurons: an input layer, 1 or more hidden layers and an output layer.\n",
    "    - each node connects to others and has its own associated weight and treshold. If the output of any indivigual node is above the specific treshold value, the node will be activated, sending data to the next layer of the network.\n",
    "    - each individual node is like its own linear regression model, composed of input data, weights, bias/treshold and an output.\n",
    "    - steps: \n",
    "        1. Input layer is determined\n",
    "        2. Weights are assigned. Weights determine the importance of any variable\n",
    "        3. ALl inputs are multiplied by their respective weights and then summed.\n",
    "        4. Output is passed through an activation function. If the output exceeds a given treshold, it activates the node and pass the data to the next layer, if it doesn't it no data is passed to the next layer.\n",
    "        5. The output of the current node will be the input of the next node. This is called as the feedforward network.\n",
    "    - MLP - multi-layer perceptrons\n",
    "    - CNN - conventional neural networks - usually utilized for image recognition, patter recognition and computer vision. Uses linear algebra and matrix multiplication.\n",
    "    - RNN - recurrent neural networks - identified by their feedback loops. Leveraged using time-series data to make predictions.\n",
    "- Clustering Algorithms - learns the clusters on train data.\n",
    "\n",
    "Things to learn:\n",
    "- containerisation - Docker, Kubernetes\n",
    "- CI/CD platforms - CircleDI\n",
    "- Version control - Git\n",
    "- Quality written code - unit test, linting, formatting, strict typing\n",
    "- Cloud platform - AWS, GCP, Azure\n",
    "- Workflow orchestration - Airflow, Argo, Metaflow\n",
    "- Experiment tracking tools - MLflow, Weights & Biases\n",
    "\n",
    "<br>\n",
    "\n",
    "- 5 things interested in:\n",
    "    - video game AI\n",
    "    - weather prediction\n",
    "    - Process automation\n",
    "    - loan defaulters prediction\n",
    "    - \n",
    "\n",
    "<br>\n",
    "\n",
    "Before running an experiment, write down:\n",
    "1. Hypothesis\n",
    "2. What is expected to happen\n",
    "3. Why expect it to happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basel Accords\n",
    "- **Regulatory capital** - minimum capital required by financial governance for banks to hold. It acts as a buffer when there's financial stress.\n",
    "- **Economic capital** - estimation by banks on how much capital they should be holding as opposed to what regulators prescribe. Regulatory capital is managed internally and would be fitted to the bank's specific risk profile and operational strategy.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Basel 1\n",
    "- First attempt to harmonize the method of bank regulation. Proposed in 1988\n",
    "- Goal: ensure maintenance of adequate capital by banks against RWA (Risk Weighted Asset - bank's assets or off balance sheet exposures, weighted according to risk), and to promote stability in the international banking system.\n",
    "- Features:\n",
    "    - Minimum 8% of RWA\n",
    "    - risk weight of 0% for cash and 100% for corporate loans\n",
    "- Weaknesses:\n",
    "    - simple methodology\n",
    "    - It did not take into account the differences in risk profiles for different types of loans and assets\n",
    "    - Banks could practice regulatory arbitrage - exploit the system through portfolio subsitution toward assets that require less regulatory capital but pose higher risks.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Basel 2\n",
    "- Introduced in 2004, to address the shortcomings of Basel 1.\n",
    "- Basel 2 is based on 3 pillars:\n",
    "    1. Minimum capital requirements - expanded on Basel 1 with more sophisticated risk weighting systems\n",
    "    2. Supervisory Review - Higlights the importance of sound regulatory oversight to ensure banks have adequate systems to manage risks\n",
    "    3. Market discipline - enhance transparency by forcing banks to disclose their risk exposures and capital adequacy postions\n",
    "- Key improvement - Internal Ratings Based (IRB) approach - enabled banks to use internal risk assessment models to calculate capital requirement.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Basel 3\n",
    "- Was developed by Basel committee in 2010 after the 2008 global financial crisis. The regulations was more stringent to prepare the financial sector against future crises.\n",
    "- Features:\n",
    "    - Higher capital standards - minimum requirement for Tier 1 capital has been increased\n",
    "    - Leverage ratio - introduced the usage of a non-risk-based leverage ratio as a backstop to the risk-weighted capital requirements to ensure the banks do not become over-leveraged. Compares a company's debt to other financial metrics like assets, equity or earnings.\n",
    "    - Liquidity requirements:\n",
    "        - liquidy coverage ratio (LCR) - ensure banks are sufficiently supplied with high-quality liquid assets to withstand a 30-day liquidity stress situation.\n",
    "        - Net stable funding ratio (NSFR) - to stimulate more stable funding with londer-term maturity.\n",
    "    - Countercyclical buffer - banks hold extra capital for buffer which they can then use during financital stress.\n",
    "- It increased the risk management of banks but the complexity of the framework depends on the bank internal models.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Basel 4\n",
    "- Ongoing process and reforms to fine tune the Basel regime.\n",
    "- Main highlights of Basel 4:\n",
    "    - Capital floors - minimum capital floors to limit the extent banks can reduce capital requirements using their internal models\n",
    "    - Standardized approach enhancements - emphasize changes in the standardized approach to the calculation of RWA on issues such as credit and operational risk.\n",
    "    - Increased disclosure - a provision to increase disclosure requirements, thereby enabling banks to give more elaborative information about their RWA and methodologies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFRS9\n",
    "- Issued by International Accounting Standards Board\n",
    "- Introduces expected loss model to early recognize potential losses by anticipating credit risk deterioration before actual default takes place\n",
    "- 3 main categories:\n",
    "    1. Amoritzed cost - Held-to-collect financial assets represent assets held for collecting contractual cash flows. spreading the cost of asset or liability over the financial lifespan accounting for the time value of money.\n",
    "    2. Fair value through other comprehensive income (FVOCI) - Held-for-collection-and-sale financial assets, whose cash flow represnt payments of principal and interest. Unrealized gains and losses are recognized in other comprehensive income.\n",
    "    3. Fair Value through Profit or Loss (FVPL) - financial assets that do not fulfill criteria of amortized cost or FVOCI are measured at fair value through profit or loss. Includes derivatives.\n",
    "- Impairment - Expected Credit Loss (ECL) model\n",
    "    - The ECL model is supposed to capture the credit losses much earlier and divided into 3 stages:\n",
    "        1. 12-month ECL - expected losses over the next 12 months, are assets for which there has not been a significant increase in credit risk  since intial recognition. *not much risk increase*\n",
    "        2. Lifetime ECL - expected losses over the entire remaining life of the asset, significant increase in credit risk since initial recognition but the asset is not yet credit-impaired. *a lot of risk since initial*\n",
    "        3. Credit-Impaired - lifetime ECL is also recognized on such assets. Interest income = gross carrying amount - loss allowance. This stage are for assets that are already in default or showing signs of default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basel Accords vs IFRS 9\n",
    "| Basel Accords | IFRS 9 |\n",
    "| --- | --- | \n",
    "| ensure capital **buffers** to absorb expected and unexpected losses | **identifying expected credit loss** for financial reporting purposes |\n",
    "| cover expected and unexpected losses | focus on expected credit losses ECL | \n",
    "| delay in payment of 90-180 days | stage 1, 2, 3 under ECL model | \n",
    "| capital buffers designed to absorb losses | recognize loss in advance before any actual default | \n",
    "\n",
    "- Probability of Default (PD) - Probability that each borrower will default in predefined time horizon.\n",
    "- Loss Given Default (LGD) - a fraction of the total exposure lost in case of a default. It measures the severity of the loss and therefore, the amount of capital to be held against the defaulters\n",
    "- Exposure at Default (EAD) - overall amount a bank may be exposed if there is a default. Includes outstanding loan amount, any increase in exposure such as undrawn credit lines up to the point of the default. Important to quantify total possible loss a bank may have to face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
